Целесообразно **регуляризировать** задачу [[Линейная регрессия (Linear regression)|линейной регрессии]] методом [[Регуляризация по Тихонову (Tikhonov regularization)|регуляризации по Тихонову]] (использовать **$L_2$-регуляризацию**). Тогда функция потерь примет вид:
$$
L_{Ridge}(w;y,X) = \lVert y-Xw \rVert_2^2 + \alpha\lVert w\rVert_2^2
$$
где $\alpha$ - коэффициент регуляризации.

В таком случае линейную регрессию называют **Ridge-регрессия**, или **гребневая регрессия**.

**Вектор параметров** $w$ равен:
$$
w=(X^\top X+\alpha E)^{-1}X^\top y
$$
где матрица $X^\top X+\alpha E$ **всегда обратима**.

**Примечание**:
В функции потерь, часть $\lVert y-Xw \rVert_2^2$ может содержать и другую норму. Это зависит от предположения, или априорной информации о [[Вероятностный подход к линейной регрессии|распределении]] случайного шума в данных.